{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1a388a-4a5d-4e3d-9505-341c618416a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with scaled features:\n",
      "   Country  Age  Salary  Age_Standardized  Salary_Standardized  \\\n",
      "0   France   44   72000          0.825723             0.480912   \n",
      "1    Spain   27   48000         -1.513825            -1.411200   \n",
      "2  Germany   30   54000         -1.100964            -0.938172   \n",
      "3    Spain   38   61000          0.000000            -0.386306   \n",
      "4  Germany   40   85000          0.275241             1.505805   \n",
      "5   France   35   58000         -0.412861            -0.622820   \n",
      "6    Spain   31   52000         -0.963343            -1.095848   \n",
      "7   France   48   79000          1.376205             1.032778   \n",
      "8  Germany   50   83000          1.651446             1.348129   \n",
      "9   France   37   67000         -0.137620             0.086722   \n",
      "\n",
      "   Age_Normalized  Salary_Normalized Purchased  \n",
      "0        0.739130           0.648649        No  \n",
      "1        0.000000           0.000000       Yes  \n",
      "2        0.130435           0.162162        No  \n",
      "3        0.478261           0.351351        No  \n",
      "4        0.565217           1.000000       Yes  \n",
      "5        0.347826           0.270270       Yes  \n",
      "6        0.173913           0.108108        No  \n",
      "7        0.913043           0.837838       Yes  \n",
      "8        1.000000           0.945946        No  \n",
      "9        0.434783           0.513514       Yes  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Create the dataset\n",
    "data = {\n",
    "    'Country': ['France', 'Spain', 'Germany', 'Spain', 'Germany', \n",
    "               'France', 'Spain', 'France', 'Germany', 'France'],\n",
    "    'Age': [44, 27, 30, 38, 40, 35, 31, 48, 50, 37],\n",
    "    'Salary': [72000, 48000, 54000, 61000, 85000, \n",
    "              58000, 52000, 79000, 83000, 67000],\n",
    "    'Purchased': ['No', 'Yes', 'No', 'No', 'Yes', \n",
    "                 'Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Select numerical features\n",
    "numerical_features = df[['Age', 'Salary']]\n",
    "\n",
    "# Standardization (Z-score normalization)\n",
    "scaler_standard = StandardScaler()\n",
    "standardized_features = scaler_standard.fit_transform(numerical_features)\n",
    "df_standardized = pd.DataFrame(standardized_features, columns=['Age_Standardized', 'Salary_Standardized'])\n",
    "\n",
    "# Normalization (Min-Max scaling)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "normalized_features = scaler_minmax.fit_transform(numerical_features)\n",
    "df_normalized = pd.DataFrame(normalized_features, columns=['Age_Normalized', 'Salary_Normalized'])\n",
    "\n",
    "# Combine results\n",
    "result = pd.concat([df, df_standardized, df_normalized], axis=1)\n",
    "print(\"Dataset with scaled features:\")\n",
    "print(result[['Country', 'Age', 'Salary', 'Age_Standardized', \n",
    "              'Salary_Standardized', 'Age_Normalized', 'Salary_Normalized', 'Purchased']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ace795-d5a8-4293-8fe1-70817ac94c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Standardize the data first\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Determine optimal number of components\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance.cumsum()\n",
    "\n",
    "print(\"Explained variance ratio:\", explained_variance)\n",
    "print(\"Cumulative explained variance:\", cumulative_variance)\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(range(1, len(explained_variance)+1), explained_variance, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(1, len(cumulative_variance)+1), cumulative_variance, where='mid', label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.show()\n",
    "\n",
    "# Visualize in 2D space (first two principal components)\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "    \n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of IRIS dataset')\n",
    "plt.xlabel('Principal Component 1 (%.2f%%)' % (explained_variance[0]*100))\n",
    "plt.ylabel('Principal Component 2 (%.2f%%)' % (explained_variance[1]*100))\n",
    "plt.show()\n",
    "\n",
    "# Create DataFrame with PCA results\n",
    "pca_df = pd.DataFrame(data=X_pca[:, :2], columns=['PC1', 'PC2'])\n",
    "pca_df['Species'] = y\n",
    "pca_df['Species'] = pca_df['Species'].map({0: target_names[0], 1: target_names[1], 2: target_names[2]})\n",
    "\n",
    "print(\"\\nFirst two principal components:\")\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ff5c6-c9b9-4973-9f96-46ef1fca7cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
